{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (25.1)\n",
      "Collecting pip\n",
      "  Using cached pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached pip-25.2-py3-none-any.whl (1.8 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "C:\\Users\\24039973\\.conda\\envs\\skincare\\python.exe -m pip install --upgrade pip\n",
      "WARNING: Skipping torch as it is not installed.\n",
      "WARNING: Skipping torchvision as it is not installed.\n",
      "WARNING: Skipping torchaudio as it is not installed.\n",
      "WARNING: Skipping xformers as it is not installed.\n",
      "WARNING: Skipping fastai as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Collecting torch==2.4.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torch-2.4.1%2Bcu124-cp312-cp312-win_amd64.whl (2506.2 MB)\n",
      "     ---------------------------------------- 0.0/2.5 GB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/2.5 GB 227.3 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.1/2.5 GB 244.8 MB/s eta 0:00:10\n",
      "     -- ------------------------------------- 0.2/2.5 GB 254.0 MB/s eta 0:00:10\n",
      "     --- ------------------------------------ 0.2/2.5 GB 255.5 MB/s eta 0:00:09\n",
      "     ---- ----------------------------------- 0.3/2.5 GB 254.0 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 0.3/2.5 GB 266.1 MB/s eta 0:00:09\n",
      "     ----- ---------------------------------- 0.4/2.5 GB 266.1 MB/s eta 0:00:09\n",
      "     ------ --------------------------------- 0.4/2.5 GB 261.9 MB/s eta 0:00:08\n",
      "     ------- -------------------------------- 0.5/2.5 GB 261.9 MB/s eta 0:00:08\n",
      "     -------- ------------------------------- 0.5/2.5 GB 254.0 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 0.6/2.5 GB 246.6 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 0.6/2.5 GB 239.6 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 0.7/2.5 GB 239.4 MB/s eta 0:00:08\n",
      "     ----------- ---------------------------- 0.7/2.5 GB 239.4 MB/s eta 0:00:08\n",
      "     ------------ --------------------------- 0.8/2.5 GB 242.9 MB/s eta 0:00:08\n",
      "     ------------- -------------------------- 0.8/2.5 GB 254.0 MB/s eta 0:00:07\n",
      "     -------------- ------------------------- 0.9/2.5 GB 250.1 MB/s eta 0:00:07\n",
      "     -------------- ------------------------- 0.9/2.5 GB 253.8 MB/s eta 0:00:07\n",
      "     --------------- ------------------------ 1.0/2.5 GB 254.0 MB/s eta 0:00:06\n",
      "     ---------------- ----------------------- 1.0/2.5 GB 257.8 MB/s eta 0:00:06\n",
      "     ----------------- ---------------------- 1.1/2.5 GB 257.8 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 1.1/2.5 GB 250.4 MB/s eta 0:00:06\n",
      "     ------------------ --------------------- 1.2/2.5 GB 239.4 MB/s eta 0:00:06\n",
      "     ------------------- -------------------- 1.2/2.5 GB 229.5 MB/s eta 0:00:06\n",
      "     -------------------- ------------------- 1.3/2.5 GB 236.1 MB/s eta 0:00:06\n",
      "     --------------------- ------------------ 1.3/2.5 GB 235.9 MB/s eta 0:00:05\n",
      "     ---------------------- ----------------- 1.4/2.5 GB 250.1 MB/s eta 0:00:05\n",
      "     ----------------------- ---------------- 1.5/2.5 GB 261.9 MB/s eta 0:00:05\n",
      "     ------------------------ --------------- 1.5/2.5 GB 261.9 MB/s eta 0:00:04\n",
      "     ------------------------ --------------- 1.6/2.5 GB 253.8 MB/s eta 0:00:04\n",
      "     ------------------------- -------------- 1.6/2.5 GB 250.1 MB/s eta 0:00:04\n",
      "     -------------------------- ------------- 1.7/2.5 GB 246.4 MB/s eta 0:00:04\n",
      "     --------------------------- ------------ 1.7/2.5 GB 246.4 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 239.4 MB/s eta 0:00:04\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 242.9 MB/s eta 0:00:03\n",
      "     ---------------------------- ----------- 1.8/2.5 GB 197.1 MB/s eta 0:00:04\n",
      "     ----------------------------- ---------- 1.9/2.5 GB 204.4 MB/s eta 0:00:04\n",
      "     ------------------------------ --------- 1.9/2.5 GB 207.0 MB/s eta 0:00:03\n",
      "     ------------------------------- -------- 2.0/2.5 GB 204.4 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 2.0/2.5 GB 197.2 MB/s eta 0:00:03\n",
      "     -------------------------------- ------- 2.1/2.5 GB 242.9 MB/s eta 0:00:02\n",
      "     --------------------------------- ------ 2.1/2.5 GB 232.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 2.2/2.5 GB 229.5 MB/s eta 0:00:02\n",
      "     ----------------------------------- ---- 2.2/2.5 GB 229.5 MB/s eta 0:00:02\n",
      "     ------------------------------------ --- 2.3/2.5 GB 246.4 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.3/2.5 GB 242.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 2.4/2.5 GB 235.9 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 239.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 215.0 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 192.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 2.4/2.5 GB 171.1 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 159.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 145.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  2.5/2.5 GB 138.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.5/2.5 GB 47.9 MB/s eta 0:00:00\n",
      "Collecting torchvision==0.19.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.19.1%2Bcu124-cp312-cp312-win_amd64.whl (5.9 MB)\n",
      "     ---------------------------------------- 0.0/5.9 MB ? eta -:--:--\n",
      "     ---------------------------------------- 5.9/5.9 MB 119.2 MB/s eta 0:00:00\n",
      "Collecting torchaudio==2.4.1\n",
      "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.4.1%2Bcu124-cp312-cp312-win_amd64.whl (4.1 MB)\n",
      "     ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 4.1/4.1 MB 257.2 MB/s eta 0:00:00\n",
      "Collecting filelock (from torch==2.4.1)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from torch==2.4.1) (4.14.1)\n",
      "Collecting sympy (from torch==2.4.1)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch==2.4.1)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch==2.4.1)\n",
      "  Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting fsspec (from torch==2.4.1)\n",
      "  Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from torch==2.4.1) (78.1.1)\n",
      "Collecting numpy (from torchvision==0.19.1)\n",
      "  Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision==0.19.1)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.4.1)\n",
      "  Downloading https://download.pytorch.org/whl/MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.4.1)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ---------------------------------------- 0.0/536.2 kB ? eta -:--:--\n",
      "     ------------------------------------- 536.2/536.2 kB 18.3 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 144.1 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Downloading https://download.pytorch.org/whl/fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Downloading https://download.pytorch.org/whl/Jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 96.0 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/numpy-2.1.2-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 12.6/12.6 MB 157.8 MB/s eta 0:00:00\n",
      "Downloading https://download.pytorch.org/whl/sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "   ---------------------------------------- 0.0/6.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 6.2/6.2 MB 191.2 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   ----------------------------------------  0/12 [mpmath]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   --- ------------------------------------  1/12 [sympy]\n",
      "   ------ ---------------------------------  2/12 [pillow]\n",
      "   ------ ---------------------------------  2/12 [pillow]\n",
      "   ------ ---------------------------------  2/12 [pillow]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ---------- -----------------------------  3/12 [numpy]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ------------- --------------------------  4/12 [networkx]\n",
      "   ---------------- -----------------------  5/12 [MarkupSafe]\n",
      "   -------------------- -------------------  6/12 [fsspec]\n",
      "   -------------------- -------------------  6/12 [fsspec]\n",
      "   -------------------------- -------------  8/12 [jinja2]\n",
      "   -------------------------- -------------  8/12 [jinja2]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   ------------------------------ ---------  9/12 [torch]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   --------------------------------- ------ 10/12 [torchvision]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ------------------------------------ --- 11/12 [torchaudio]\n",
      "   ---------------------------------------- 12/12 [torchaudio]\n",
      "\n",
      "Successfully installed MarkupSafe-2.1.5 filelock-3.13.1 fsspec-2024.6.1 jinja2-3.1.4 mpmath-1.3.0 networkx-3.3 numpy-2.1.2 pillow-11.0.0 sympy-1.13.3 torch-2.4.1+cu124 torchaudio-2.4.1+cu124 torchvision-0.19.1+cu124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: Building 'xformers' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'xformers'. Discussion can be found at https://github.com/pypa/pip/issues/6334\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [238 lines of output]\n",
      "      fatal: not a git repository (or any of the parent directories): .git\n",
      "      C:\\Users\\24039973\\.conda\\envs\\skincare\\Lib\\site-packages\\setuptools\\dist.py:759: SetuptoolsDeprecationWarning: License classifiers are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Please consider removing the following classifiers in favor of a SPDX license expression:\n",
      "      \n",
      "              License :: OSI Approved :: BSD License\n",
      "      \n",
      "              See https://packaging.python.org/en/latest/guides/writing-pyproject-toml/#license for details.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        self._finalize_license_expression()\n",
      "      running bdist_wheel\n",
      "      C:\\Users\\24039973\\.conda\\envs\\skincare\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:495: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
      "        warnings.warn(msg.format('we could not find ninja.'))\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\n",
      "      copying xformers\\attn_bias_utils.py -> build\\lib.win-amd64-cpython-312\\xformers\n",
      "      copying xformers\\checkpoint.py -> build\\lib.win-amd64-cpython-312\\xformers\n",
      "      copying xformers\\info.py -> build\\lib.win-amd64-cpython-312\\xformers\n",
      "      copying xformers\\test.py -> build\\lib.win-amd64-cpython-312\\xformers\n",
      "      copying xformers\\utils.py -> build\\lib.win-amd64-cpython-312\\xformers\n",
      "      copying xformers\\_cpp_lib.py -> build\\lib.win-amd64-cpython-312\\xformers\n",
      "      copying xformers\\_deprecation_warning.py -> build\\lib.win-amd64-cpython-312\\xformers\n",
      "      copying xformers\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_attn_decoding.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_core.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_indexing.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_mem_eff_attention.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_merge_attentions.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_multi_head_dispatch.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_nystrom_utils.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_revnet.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_sddmm.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_sequence_parallel_fused.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_sp24.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_swiglu.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\benchmark_tiled_matmul.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\utils.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      copying xformers\\benchmarks\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      copying xformers\\components\\activations.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      copying xformers\\components\\input_projection.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      copying xformers\\components\\multi_head_dispatch.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      copying xformers\\components\\patch_embedding.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      copying xformers\\components\\residual.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      copying xformers\\components\\reversible.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      copying xformers\\components\\simplicial_embedding.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      copying xformers\\components\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\factory\n",
      "      copying xformers\\factory\\block_configs.py -> build\\lib.win-amd64-cpython-312\\xformers\\factory\n",
      "      copying xformers\\factory\\block_factory.py -> build\\lib.win-amd64-cpython-312\\xformers\\factory\n",
      "      copying xformers\\factory\\hydra_helper.py -> build\\lib.win-amd64-cpython-312\\xformers\\factory\n",
      "      copying xformers\\factory\\model_factory.py -> build\\lib.win-amd64-cpython-312\\xformers\\factory\n",
      "      copying xformers\\factory\\weight_init.py -> build\\lib.win-amd64-cpython-312\\xformers\\factory\n",
      "      copying xformers\\factory\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\factory\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\helpers\n",
      "      copying xformers\\helpers\\hierarchical_configs.py -> build\\lib.win-amd64-cpython-312\\xformers\\helpers\n",
      "      copying xformers\\helpers\\test_utils.py -> build\\lib.win-amd64-cpython-312\\xformers\\helpers\n",
      "      copying xformers\\helpers\\timm_sparse_attention.py -> build\\lib.win-amd64-cpython-312\\xformers\\helpers\n",
      "      copying xformers\\helpers\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\helpers\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\common.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\differentiable_collectives.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\indexing.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\ipc.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\modpar_layers.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\rmsnorm.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\rope_padded.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\seqpar.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\sequence_parallel_fused_ops.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\sp24.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\swiglu_op.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\tiled_matmul.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\unbind.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      copying xformers\\ops\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      copying xformers\\profiler\\api.py -> build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      copying xformers\\profiler\\device_limits.py -> build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      copying xformers\\profiler\\find_slowest.py -> build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      copying xformers\\profiler\\profiler.py -> build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      copying xformers\\profiler\\profiler_dcgm.py -> build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      copying xformers\\profiler\\profiler_dcgm_impl.py -> build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      copying xformers\\profiler\\profile_analyzer.py -> build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      copying xformers\\profiler\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\profiler\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\sparse\n",
      "      copying xformers\\sparse\\blocksparse_tensor.py -> build\\lib.win-amd64-cpython-312\\xformers\\sparse\n",
      "      copying xformers\\sparse\\csr_tensor.py -> build\\lib.win-amd64-cpython-312\\xformers\\sparse\n",
      "      copying xformers\\sparse\\utils.py -> build\\lib.win-amd64-cpython-312\\xformers\\sparse\n",
      "      copying xformers\\sparse\\_csr_ops.py -> build\\lib.win-amd64-cpython-312\\xformers\\sparse\n",
      "      copying xformers\\sparse\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\sparse\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\triton\n",
      "      copying xformers\\triton\\vararg_kernel.py -> build\\lib.win-amd64-cpython-312\\xformers\\triton\n",
      "      copying xformers\\triton\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\triton\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\bert_padding.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_attn_interface.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_attn_triton.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_attn_triton_og.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_blocksparse_attention.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\flash_blocksparse_attn_interface.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\fused_softmax.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      copying xformers\\_flash_attn\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\batch_fetch_results.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\batch_submit.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\run_grid_search.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\run_tasks.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\run_with_submitit.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\n",
      "      copying xformers\\benchmarks\\LRA\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\\code\n",
      "      copying xformers\\benchmarks\\LRA\\code\\dataset.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\\code\n",
      "      copying xformers\\benchmarks\\LRA\\code\\model_wrapper.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\\code\n",
      "      copying xformers\\benchmarks\\LRA\\code\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\benchmarks\\LRA\\code\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\attention_mask.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\attention_patterns.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\base.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\compositional.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\core.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\favor.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\fourier_mix.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\global_tokens.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\lambda_layer.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\linformer.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\local.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\nystrom.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\ortho.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\pooling.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\random.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\scaled_dot_product.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\sparsity_config.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\utils.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\visual.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\_sputnik_sparse.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      copying xformers\\components\\attention\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\base.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\conv_mlp.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\mixture_of_experts.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\mlp.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\feedforward\n",
      "      copying xformers\\components\\feedforward\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\feedforward\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\base.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\param.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\rotary.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\sine.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\vocab.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\positional_embedding\n",
      "      copying xformers\\components\\positional_embedding\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\positional_embedding\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\\feature_maps\n",
      "      copying xformers\\components\\attention\\feature_maps\\base.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\\feature_maps\n",
      "      copying xformers\\components\\attention\\feature_maps\\softmax.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\\feature_maps\n",
      "      copying xformers\\components\\attention\\feature_maps\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\components\\attention\\feature_maps\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\attn_bias.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\ck.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\ck_decoder.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\ck_splitk.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\common.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\cutlass.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\dispatch.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\flash.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\flash3.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\torch_attention_compat.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\triton_splitk.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      copying xformers\\ops\\fmha\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\fmha\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\k_index_select_cat.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\k_scaled_index_add.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\rmsnorm_kernels.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\rope_padded_kernels.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\sequence_parallel_fused_kernels.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\tiled_matmul_kernels.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\_triton\n",
      "      copying xformers\\ops\\_triton\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\ops\\_triton\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\layers\n",
      "      copying xformers\\_flash_attn\\layers\\patch_embed.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\layers\n",
      "      copying xformers\\_flash_attn\\layers\\rotary.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\layers\n",
      "      copying xformers\\_flash_attn\\layers\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\layers\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\losses\n",
      "      copying xformers\\_flash_attn\\losses\\cross_entropy.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\losses\n",
      "      copying xformers\\_flash_attn\\losses\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\losses\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\baichuan.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\bert.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\bigcode.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\btlm.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\falcon.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\gpt.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\gptj.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\gpt_neox.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\llama.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\opt.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\vit.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      copying xformers\\_flash_attn\\models\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\models\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\block.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\embedding.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\mha.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\mlp.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\modules\n",
      "      copying xformers\\_flash_attn\\modules\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\modules\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\activations.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\fused_dense.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\layer_norm.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\rms_norm.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\n",
      "      copying xformers\\_flash_attn\\ops\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\benchmark.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\distributed.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\generation.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\pretrained.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\utils\n",
      "      copying xformers\\_flash_attn\\utils\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\utils\n",
      "      creating build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\cross_entropy.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\k_activations.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\layer_norm.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\linear.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\mlp.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\rotary.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\\triton\n",
      "      copying xformers\\_flash_attn\\ops\\triton\\__init__.py -> build\\lib.win-amd64-cpython-312\\xformers\\_flash_attn\\ops\\triton\n",
      "      running build_ext\n",
      "      C:\\Users\\24039973\\.conda\\envs\\skincare\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:380: UserWarning: Error checking compiler version for cl: [WinError 2] The system cannot find the file specified\n",
      "        warnings.warn(f'Error checking compiler version for {compiler}: {error}')\n",
      "      C:\\Users\\24039973\\.conda\\envs\\skincare\\Lib\\site-packages\\torch\\utils\\cpp_extension.py:414: UserWarning: The detected CUDA version (12.5) has a minor version mismatch with the version that was used to compile PyTorch (12.4). Most likely this shouldn't be a problem.\n",
      "        warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
      "      building 'xformers._C_flashattention' extension\n",
      "      creating build\\temp.win-amd64-cpython-312\\Release\\Users\\24039973\\AppData\\Local\\Temp\\pip-install-8cmvcvu0\\xformers_0de797625b0242539d2e6789850c693d\\third_party\\flash-attention\\csrc\\flash_attn\n",
      "      creating build\\temp.win-amd64-cpython-312\\Release\\Users\\24039973\\AppData\\Local\\Temp\\pip-install-8cmvcvu0\\xformers_0de797625b0242539d2e6789850c693d\\third_party\\flash-attention\\csrc\\flash_attn\\src\n",
      "      \"C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.44.35207\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -IC:\\Users\\24039973\\AppData\\Local\\Temp\\pip-install-8cmvcvu0\\xformers_0de797625b0242539d2e6789850c693d\\third_party\\flash-attention\\csrc\\flash_attn -IC:\\Users\\24039973\\AppData\\Local\\Temp\\pip-install-8cmvcvu0\\xformers_0de797625b0242539d2e6789850c693d\\third_party\\flash-attention\\csrc\\flash_attn\\src -IC:\\Users\\24039973\\AppData\\Local\\Temp\\pip-install-8cmvcvu0\\xformers_0de797625b0242539d2e6789850c693d\\third_party\\flash-attention\\csrc\\cutlass\\include -IC:\\Users\\24039973\\.conda\\envs\\skincare\\Lib\\site-packages\\torch\\include -IC:\\Users\\24039973\\.conda\\envs\\skincare\\Lib\\site-packages\\torch\\include\\torch\\csrc\\api\\include -IC:\\Users\\24039973\\.conda\\envs\\skincare\\Lib\\site-packages\\torch\\include\\TH -IC:\\Users\\24039973\\.conda\\envs\\skincare\\Lib\\site-packages\\torch\\include\\THC \"-IC:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v12.5\\include\" -IC:\\Users\\24039973\\.conda\\envs\\skincare\\include -IC:\\Users\\24039973\\.conda\\envs\\skincare\\Include \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.44.35207\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.44.35207\\ATLMFC\\include\" \"-IC:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" /EHsc /TpC:\\Users\\24039973\\AppData\\Local\\Temp\\pip-install-8cmvcvu0\\xformers_0de797625b0242539d2e6789850c693d\\third_party\\flash-attention\\csrc/flash_attn/flash_api.cpp /Fobuild\\temp.win-amd64-cpython-312\\Release\\Users\\24039973\\AppData\\Local\\Temp\\pip-install-8cmvcvu0\\xformers_0de797625b0242539d2e6789850c693d\\third_party\\flash-attention\\csrc\\flash_attn\\flash_api.obj /MD /wd4819 /wd4251 /wd4244 /wd4267 /wd4275 /wd4018 /wd4190 /wd4624 /wd4067 /wd4068 /EHsc -O3 -std=c++17 /MP /Zc:lambda /Zc:preprocessor /Zc:__cplusplus -DFLASHATTENTION_DISABLE_ALIBI -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C_flashattention -D_GLIBCXX_USE_CXX11_ABI=0 /std:c++17\n",
      "      cl : Command line warning D9002 : ignoring unknown option '-O3'\n",
      "      cl : Command line warning D9002 : ignoring unknown option '-std=c++17'\n",
      "      flash_api.cpp\n",
      "      C:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.44.35207\\include\\cstddef(11): fatal error C1083: Cannot open include file: 'stddef.h': No such file or directory\n",
      "      error: command 'C:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.44.35207\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for xformers\n",
      "ERROR: Failed to build installable wheels for some pyproject.toml based projects (xformers)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip uninstall -y torch torchvision torchaudio xformers fastai || true\n",
    "!pip install --index-url https://download.pytorch.org/whl/cu124 \\\n",
    "  torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n",
    "\n",
    "# Core libs (pick versions that play nicely with torch 2.4.x)\n",
    "!pip install \\\n",
    "  transformers>=4.43 \\\n",
    "  datasets>=2.20 \\\n",
    "  peft>=0.12 \\\n",
    "  accelerate>=0.33 \\\n",
    "  trl>=0.9.4 \\\n",
    "  bitsandbytes>=0.44.1 \\\n",
    "  xformers==0.0.28.post1 \\\n",
    "  huggingface_hub>=0.24 \\\n",
    "  unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\n",
      "  Using cached datasets-4.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets) (2.1.2)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Using cached pyarrow-21.0.0-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.32.2 (from datasets)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm>=4.66.3 (from datasets)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.6.1)\n",
      "Collecting huggingface-hub>=0.24.0 (from datasets)\n",
      "  Using cached huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets) (25.0)\n",
      "Collecting pyyaml>=5.1 (from datasets)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohttp-3.12.15-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached multidict-6.6.4-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "Collecting idna>=2.0 (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (4.14.1)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets)\n",
      "  Using cached charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl.metadata (37 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.32.2->datasets)\n",
      "  Using cached certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading datasets-4.0.0-py3-none-any.whl (494 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached aiohttp-3.12.15-cp312-cp312-win_amd64.whl (450 kB)\n",
      "Using cached multidict-6.6.4-cp312-cp312-win_amd64.whl (46 kB)\n",
      "Using cached yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "Using cached huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached pyarrow-21.0.0-cp312-cp312-win_amd64.whl (26.2 MB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached pandas-2.3.1-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Installing collected packages: pytz, xxhash, urllib3, tzdata, tqdm, pyyaml, pyarrow, propcache, multidict, idna, frozenlist, dill, charset_normalizer, certifi, attrs, aiohappyeyeballs, yarl, requests, pandas, multiprocess, aiosignal, huggingface-hub, aiohttp, datasets\n",
      "\n",
      "   ----------------------------------------  0/24 [pytz]\n",
      "   ----------------------------------------  0/24 [pytz]\n",
      "   --- ------------------------------------  2/24 [urllib3]\n",
      "   ----- ----------------------------------  3/24 [tzdata]\n",
      "   ----- ----------------------------------  3/24 [tzdata]\n",
      "   ----- ----------------------------------  3/24 [tzdata]\n",
      "   ------ ---------------------------------  4/24 [tqdm]\n",
      "   -------- -------------------------------  5/24 [pyyaml]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   ---------- -----------------------------  6/24 [pyarrow]\n",
      "   --------------- ------------------------  9/24 [idna]\n",
      "   ------------------ --------------------- 11/24 [dill]\n",
      "   -------------------- ------------------- 12/24 [charset_normalizer]\n",
      "   -------------------------- ------------- 16/24 [yarl]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------ --------- 18/24 [pandas]\n",
      "   ------------------------------- -------- 19/24 [multiprocess]\n",
      "   ------------------------------- -------- 19/24 [multiprocess]\n",
      "   --------------------------------- ------ 20/24 [aiosignal]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ----------------------------------- ---- 21/24 [huggingface-hub]\n",
      "   ------------------------------------ --- 22/24 [aiohttp]\n",
      "   ------------------------------------ --- 22/24 [aiohttp]\n",
      "   ------------------------------------ --- 22/24 [aiohttp]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   -------------------------------------- - 23/24 [datasets]\n",
      "   ---------------------------------------- 24/24 [datasets]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 attrs-25.3.0 certifi-2025.8.3 charset_normalizer-3.4.3 datasets-4.0.0 dill-0.3.8 frozenlist-1.7.0 huggingface-hub-0.34.4 idna-3.10 multidict-6.6.4 multiprocess-0.70.16 pandas-2.3.1 propcache-0.3.2 pyarrow-21.0.0 pytz-2025.2 pyyaml-6.0.2 requests-2.32.5 tqdm-4.67.1 tzdata-2025.2 urllib3-2.5.0 xxhash-3.5.0 yarl-1.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (2025.8.9)\n",
      "Requirement already satisfied: unsloth_zoo>=2025.8.8 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (2025.8.8)\n",
      "Requirement already satisfied: torch>=2.4.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (2.8.0)\n",
      "Requirement already satisfied: xformers>=0.0.27.post2 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.0.32.post2)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.47.0)\n",
      "Requirement already satisfied: triton-windows in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (3.4.0.post20)\n",
      "Requirement already satisfied: packaging in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: tyro in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.9.28)\n",
      "Requirement already satisfied: transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (4.55.2)\n",
      "Requirement already satisfied: datasets<4.0.0,>=3.4.1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (3.6.0)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.2.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (5.9.0)\n",
      "Requirement already satisfied: wheel>=0.42.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (2.1.2)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (1.10.0)\n",
      "Requirement already satisfied: trl!=0.15.0,!=0.19.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.21.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.17.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (6.32.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.34.4)\n",
      "Requirement already satisfied: hf_transfer in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.35.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth) (0.23.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.3.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (2.32.5)\n",
      "Requirement already satisfied: xxhash in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2024.6.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from datasets<4.0.0,>=3.4.1->unsloth) (6.0.2)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.12.15)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from accelerate>=0.34.1->unsloth) (0.6.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (3.10)\n",
      "Requirement already satisfied: typing-extensions>=4.2 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from aiosignal>=1.4.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets<4.0.0,>=3.4.1->unsloth) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (3.4.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from requests>=2.32.2->datasets<4.0.0,>=3.4.1->unsloth) (2025.8.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from torch>=2.4.0->unsloth) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from torch>=2.4.0->unsloth) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from torch>=2.4.0->unsloth) (78.1.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from tqdm->unsloth) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth) (2025.7.34)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from transformers!=4.47.0,!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,>=4.51.3->unsloth) (0.21.4)\n",
      "Requirement already satisfied: torchao in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth_zoo>=2025.8.8->unsloth) (0.12.0)\n",
      "Requirement already satisfied: cut_cross_entropy in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth_zoo>=2025.8.8->unsloth) (25.1.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth_zoo>=2025.8.8->unsloth) (11.0.0)\n",
      "Requirement already satisfied: msgspec in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from unsloth_zoo>=2025.8.8->unsloth) (0.19.0)\n",
      "Requirement already satisfied: importlib_metadata in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from diffusers->unsloth) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from jinja2->torch>=2.4.0->unsloth) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from pandas->datasets<4.0.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets<4.0.0,>=3.4.1->unsloth) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: rich>=11.1.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from tyro->unsloth) (14.1.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from tyro->unsloth) (1.7.2)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from tyro->unsloth) (4.4.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from rich>=11.1.0->tyro->unsloth) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (2286457287.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtorch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "!pip install --index-url https://download.pytorch.org/whl/cu121 `\n",
    "  torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'pytorch'\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch torchvision torchaudio -c pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer in c:\\users\\24039973\\.conda\\envs\\skincare\\lib\\site-packages (3.3.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install charset-normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (559185980.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython -c \"import torch; print('cuda.is_available:', torch.cuda.is_available()); print('version:', torch.__version__); print('built with CUDA:', torch.backends.cuda.is_built()); print('torch.version.cuda:', torch.version.cuda)\"\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (865018351.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mtorch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "!pip install --index-url https://download.pytorch.org/whl/cu121 `\n",
    "  torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.8.0\n",
      "Uninstalling torch-2.8.0:\n",
      "  Successfully uninstalled torch-2.8.0\n",
      "Found existing installation: torchvision 0.23.0\n",
      "Uninstalling torchvision-0.23.0:\n",
      "  Successfully uninstalled torchvision-0.23.0\n",
      "Found existing installation: torchaudio 2.4.1+cu124\n",
      "Uninstalling torchaudio-2.4.1+cu124:\n",
      "  Successfully uninstalled torchaudio-2.4.1+cu124\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y torch torchvision torchaudio\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skincare",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
